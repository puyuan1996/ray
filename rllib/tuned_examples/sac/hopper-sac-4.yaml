Hopper-v3-sac-gpu-seed4:  # TODO(pu)
    env: Hopper-v3
    run: SAC
    checkpoint_freq: 10000000  # TODO(pu):1e7
    stop:
        episode_reward_mean: 3000
        timesteps_total: 3000000 # 3M
        # time_total_s: 72000  # 72000 s=20 hours
    config:
        seed: 4  # TODO(pu)
        # Works for both torch and tf.
        framework: torch
        horizon: 1000
        soft_horizon: false
        Q_model:
          fcnet_activation: relu
          fcnet_hiddens: [256, 256]
        policy_model:
          fcnet_activation: relu
          fcnet_hiddens: [256, 256]
        tau: 0.005
        target_entropy: auto
        no_done_at_end: false
        n_step: 1
        rollout_fragment_length: 1
        prioritized_replay: true
        train_batch_size: 256
        target_network_update_freq: 1
        timesteps_per_iteration: 1000
        learning_starts: 10000
        optimization:
          actor_learning_rate: 0.0003
          critic_learning_rate: 0.0003
          entropy_learning_rate: 0.0003
        clip_actions: false
        normalize_actions: true
        evaluation_interval: 5
        metrics_smoothing_episodes: 5

        num_gpus: 0.5 # TODO(pu):1
        num_cpus_for_driver: 8  # TODO(pu): Number of CPUs to allocate for the trainer. 
        num_workers: 8  # TODO(pu): Number of rollout worker actors to create for parallel sampling.
        num_gpus_per_worker: 0.0415
        num_cpus_per_worker: 2
        evaluation_num_workers: 4  # TODO(pu): Number of parallel workers to use for evaluation.
        timesteps_per_iteration: 10000
        evaluation_interval: 5
        evaluation_num_episodes: 10

